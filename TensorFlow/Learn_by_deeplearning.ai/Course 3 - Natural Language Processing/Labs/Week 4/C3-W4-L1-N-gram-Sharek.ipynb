{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'and': 1, 'the': 2, 'a': 3, 'in': 4, 'all': 5, 'i': 6, 'for': 7, 'of': 8, 'lanigans': 9, 'ball': 10, 'were': 11, 'at': 12, 'to': 13, 'she': 14, 'stepped': 15, 'his': 16, 'girls': 17, 'as': 18, 'they': 19, 'til': 20, 'he': 21, 'again': 22, 'got': 23, 'boys': 24, 'round': 25, 'that': 26, 'her': 27, 'there': 28, 'three': 29, 'weeks': 30, 'up': 31, 'out': 32, 'him': 33, 'was': 34, 'spent': 35, 'learning': 36, 'new': 37, 'steps': 38, 'long': 39, 'away': 40, 'left': 41, 'friends': 42, 'relations': 43, 'when': 44, 'wall': 45, 'myself': 46, 'nice': 47, 'just': 48, 'dancing': 49, 'merry': 50, 'tipped': 51, 'me': 52, 'soon': 53, 'time': 54, 'old': 55, 'their': 56, 'them': 57, 'danced': 58, 'dublin': 59, 'an': 60, 'put': 61, 'leg': 62, 'miss': 63, 'fainted': 64, 'from': 65, 'town': 66, 'athy': 67, 'one': 68, 'jeremy': 69, 'lanigan': 70, 'battered': 71, 'hadnt': 72, 'pound': 73, 'father': 74, 'died': 75, 'made': 76, 'man': 77, 'farm': 78, 'ten': 79, 'acres': 80, 'ground': 81, 'gave': 82, 'grand': 83, 'party': 84, 'who': 85, 'didnt': 86, 'forget': 87, 'come': 88, 'if': 89, 'youll': 90, 'but': 91, 'listen': 92, 'ill': 93, 'make': 94, 'your': 95, 'eyes': 96, 'glisten': 97, 'rows': 98, 'ructions': 99, 'be': 100, 'sure': 101, 'free': 102, 'invitation': 103, 'might': 104, 'ask': 105, 'minute': 106, 'both': 107, 'bees': 108, 'cask': 109, 'judy': 110, 'odaly': 111, 'little': 112, 'milliner': 113, 'wink': 114, 'give': 115, 'call': 116, 'arrived': 117, 'with': 118, 'peggy': 119, 'mcgilligan': 120, 'lashings': 121, 'punch': 122, 'wine': 123, 'ladies': 124, 'potatoes': 125, 'cakes': 126, 'bacon': 127, 'tea': 128, 'nolans': 129, 'dolans': 130, 'ogradys': 131, 'courting': 132, 'songs': 133, 'went': 134, 'plenty': 135, 'water': 136, 'harp': 137, 'once': 138, 'sounded': 139, 'taras': 140, 'hall': 141, 'sweet': 142, 'nelly': 143, 'gray': 144, 'rat': 145, 'catchers': 146, 'daughter': 147, 'singing': 148, 'together': 149, 'doing': 150, 'kinds': 151, 'nonsensical': 152, 'polkas': 153, 'room': 154, 'whirligig': 155, 'julia': 156, 'we': 157, 'banished': 158, 'nonsense': 159, 'twist': 160, 'reel': 161, 'jig': 162, 'ach': 163, 'mavrone': 164, 'how': 165, 'mad': 166, 'youd': 167, 'think': 168, 'ceiling': 169, 'would': 170, 'fall': 171, 'brooks': 172, 'academy': 173, 'learn': 174, 'nothing': 175, 'hearty': 176, 'around': 177, 'couples': 178, 'groups': 179, 'accident': 180, 'happened': 181, 'young': 182, 'terrance': 183, 'mccarthy': 184, 'right': 185, 'through': 186, 'finnertys': 187, 'hoops': 188, 'poor': 189, 'creature': 190, 'cried': 191, 'meelia': 192, 'murther': 193, 'called': 194, 'brothers': 195, 'gathered': 196, 'carmody': 197, 'swore': 198, 'hed': 199, 'go': 200, 'no': 201, 'further': 202, 'had': 203, 'satisfaction': 204, 'midst': 205, 'row': 206, 'kerrigan': 207, 'cheeks': 208, 'same': 209, 'red': 210, 'rose': 211, 'some': 212, 'lads': 213, 'declared': 214, 'painted': 215, 'took': 216, 'small': 217, 'drop': 218, 'too': 219, 'much': 220, 'suppose': 221, 'sweetheart': 222, 'ned': 223, 'morgan': 224, 'so': 225, 'powerful': 226, 'able': 227, 'saw': 228, 'fair': 229, 'colleen': 230, 'stretched': 231, 'by': 232, 'tore': 233, 'under': 234, 'table': 235, 'smashed': 236, 'chaneys': 237, 'oh': 238, 'twas': 239, 'then': 240, 'runctions': 241, 'lick': 242, 'big': 243, 'phelim': 244, 'mchugh': 245, 'replied': 246, 'introduction': 247, 'kicked': 248, 'terrible': 249, 'hullabaloo': 250, 'casey': 251, 'piper': 252, 'near': 253, 'being': 254, 'strangled': 255, 'squeezed': 256, 'pipes': 257, 'bellows': 258, 'chanters': 259, 'ribbons': 260, 'entangled': 261, 'end': 262}\n",
      "263\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "\n",
    "data=\"In the town of Athy one Jeremy Lanigan \\n Battered away til he hadnt a pound. \\nHis father died and made him a man again \\n Left him a farm and ten acres of ground. \\nHe gave a grand party for friends and relations \\nWho didnt forget him when come to the wall, \\nAnd if youll but listen Ill make your eyes glisten \\nOf the rows and the ructions of Lanigans Ball. \\nMyself to be sure got free invitation, \\nFor all the nice girls and boys I might ask, \\nAnd just in a minute both friends and relations \\nWere dancing round merry as bees round a cask. \\nJudy ODaly, that nice little milliner, \\nShe tipped me a wink for to give her a call, \\nAnd I soon arrived with Peggy McGilligan \\nJust in time for Lanigans Ball. \\nThere were lashings of punch and wine for the ladies, \\nPotatoes and cakes; there was bacon and tea, \\nThere were the Nolans, Dolans, OGradys \\nCourting the girls and dancing away. \\nSongs they went round as plenty as water, \\nThe harp that once sounded in Taras old hall,\\nSweet Nelly Gray and The Rat Catchers Daughter,\\nAll singing together at Lanigans Ball. \\nThey were doing all kinds of nonsensical polkas \\nAll round the room in a whirligig. \\nJulia and I, we banished their nonsense \\nAnd tipped them the twist of a reel and a jig. \\nAch mavrone, how the girls got all mad at me \\nDanced til youd think the ceiling would fall. \\nFor I spent three weeks at Brooks Academy \\nLearning new steps for Lanigans Ball. \\nThree long weeks I spent up in Dublin, \\nThree long weeks to learn nothing at all,\\n Three long weeks I spent up in Dublin, \\nLearning new steps for Lanigans Ball. \\nShe stepped out and I stepped in again, \\nI stepped out and she stepped in again, \\nShe stepped out and I stepped in again, \\nLearning new steps for Lanigans Ball. \\nBoys were all merry and the girls they were hearty \\nAnd danced all around in couples and groups, \\nTil an accident happened, young Terrance McCarthy \\nPut his right leg through miss Finnertys hoops. \\nPoor creature fainted and cried Meelia murther, \\nCalled for her brothers and gathered them all. \\nCarmody swore that hed go no further \\nTil he had satisfaction at Lanigans Ball. \\nIn the midst of the row miss Kerrigan fainted, \\nHer cheeks at the same time as red as a rose. \\nSome of the lads declared she was painted, \\nShe took a small drop too much, I suppose. \\nHer sweetheart, Ned Morgan, so powerful and able, \\nWhen he saw his fair colleen stretched out by the wall, \\nTore the left leg from under the table \\nAnd smashed all the Chaneys at Lanigans Ball. \\nBoys, oh boys, twas then there were runctions. \\nMyself got a lick from big Phelim McHugh. \\nI soon replied to his introduction \\nAnd kicked up a terrible hullabaloo. \\nOld Casey, the piper, was near being strangled. \\nThey squeezed up his pipes, bellows, chanters and all. \\nThe girls, in their ribbons, they got all entangled \\nAnd that put an end to Lanigans Ball.\"\n",
    "\n",
    "corpus = data.lower().split(\"\\n\")\n",
    "\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "\n",
    "print(tokenizer.word_index)\n",
    "print(total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequences = []\n",
    "for line in corpus:\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i+1]\n",
    "        input_sequences.append(n_gram_sequence)\n",
    "\n",
    "# pad sequences \n",
    "max_sequence_len = max([len(x) for x in input_sequences])\n",
    "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
    "\n",
    "# create predictors and label\n",
    "xs, labels = input_sequences[:,:-1],input_sequences[:,-1]\n",
    "\n",
    "# one-hot code\n",
    "ys = tf.keras.utils.to_categorical(labels, num_classes=total_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**n-gram:**\n",
    "\n",
    "![jupyter](./n-gram.png)\n",
    "\n",
    "\n",
    "**padded-sequence:**\n",
    "![jupyter](./padded-sequence.png)\n",
    "\n",
    "\n",
    "**labeled:**\n",
    "![jupyter](./fig.png)\n",
    "![jupyter](./fig2.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "2\n",
      "66\n",
      "8\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.word_index['in'])\n",
    "print(tokenizer.word_index['the'])\n",
    "print(tokenizer.word_index['town'])\n",
    "print(tokenizer.word_index['of'])\n",
    "print(tokenizer.word_index['athy'])\n",
    "print(tokenizer.word_index['one'])\n",
    "print(tokenizer.word_index['jeremy'])\n",
    "print(tokenizer.word_index['lanigan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  0  0  4  2 66  8 67 68 69]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(xs[6])\n",
    "print(ys[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'and': 1, 'the': 2, 'a': 3, 'in': 4, 'all': 5, 'i': 6, 'for': 7, 'of': 8, 'lanigans': 9, 'ball': 10, 'were': 11, 'at': 12, 'to': 13, 'she': 14, 'stepped': 15, 'his': 16, 'girls': 17, 'as': 18, 'they': 19, 'til': 20, 'he': 21, 'again': 22, 'got': 23, 'boys': 24, 'round': 25, 'that': 26, 'her': 27, 'there': 28, 'three': 29, 'weeks': 30, 'up': 31, 'out': 32, 'him': 33, 'was': 34, 'spent': 35, 'learning': 36, 'new': 37, 'steps': 38, 'long': 39, 'away': 40, 'left': 41, 'friends': 42, 'relations': 43, 'when': 44, 'wall': 45, 'myself': 46, 'nice': 47, 'just': 48, 'dancing': 49, 'merry': 50, 'tipped': 51, 'me': 52, 'soon': 53, 'time': 54, 'old': 55, 'their': 56, 'them': 57, 'danced': 58, 'dublin': 59, 'an': 60, 'put': 61, 'leg': 62, 'miss': 63, 'fainted': 64, 'from': 65, 'town': 66, 'athy': 67, 'one': 68, 'jeremy': 69, 'lanigan': 70, 'battered': 71, 'hadnt': 72, 'pound': 73, 'father': 74, 'died': 75, 'made': 76, 'man': 77, 'farm': 78, 'ten': 79, 'acres': 80, 'ground': 81, 'gave': 82, 'grand': 83, 'party': 84, 'who': 85, 'didnt': 86, 'forget': 87, 'come': 88, 'if': 89, 'youll': 90, 'but': 91, 'listen': 92, 'ill': 93, 'make': 94, 'your': 95, 'eyes': 96, 'glisten': 97, 'rows': 98, 'ructions': 99, 'be': 100, 'sure': 101, 'free': 102, 'invitation': 103, 'might': 104, 'ask': 105, 'minute': 106, 'both': 107, 'bees': 108, 'cask': 109, 'judy': 110, 'odaly': 111, 'little': 112, 'milliner': 113, 'wink': 114, 'give': 115, 'call': 116, 'arrived': 117, 'with': 118, 'peggy': 119, 'mcgilligan': 120, 'lashings': 121, 'punch': 122, 'wine': 123, 'ladies': 124, 'potatoes': 125, 'cakes': 126, 'bacon': 127, 'tea': 128, 'nolans': 129, 'dolans': 130, 'ogradys': 131, 'courting': 132, 'songs': 133, 'went': 134, 'plenty': 135, 'water': 136, 'harp': 137, 'once': 138, 'sounded': 139, 'taras': 140, 'hall': 141, 'sweet': 142, 'nelly': 143, 'gray': 144, 'rat': 145, 'catchers': 146, 'daughter': 147, 'singing': 148, 'together': 149, 'doing': 150, 'kinds': 151, 'nonsensical': 152, 'polkas': 153, 'room': 154, 'whirligig': 155, 'julia': 156, 'we': 157, 'banished': 158, 'nonsense': 159, 'twist': 160, 'reel': 161, 'jig': 162, 'ach': 163, 'mavrone': 164, 'how': 165, 'mad': 166, 'youd': 167, 'think': 168, 'ceiling': 169, 'would': 170, 'fall': 171, 'brooks': 172, 'academy': 173, 'learn': 174, 'nothing': 175, 'hearty': 176, 'around': 177, 'couples': 178, 'groups': 179, 'accident': 180, 'happened': 181, 'young': 182, 'terrance': 183, 'mccarthy': 184, 'right': 185, 'through': 186, 'finnertys': 187, 'hoops': 188, 'poor': 189, 'creature': 190, 'cried': 191, 'meelia': 192, 'murther': 193, 'called': 194, 'brothers': 195, 'gathered': 196, 'carmody': 197, 'swore': 198, 'hed': 199, 'go': 200, 'no': 201, 'further': 202, 'had': 203, 'satisfaction': 204, 'midst': 205, 'row': 206, 'kerrigan': 207, 'cheeks': 208, 'same': 209, 'red': 210, 'rose': 211, 'some': 212, 'lads': 213, 'declared': 214, 'painted': 215, 'took': 216, 'small': 217, 'drop': 218, 'too': 219, 'much': 220, 'suppose': 221, 'sweetheart': 222, 'ned': 223, 'morgan': 224, 'so': 225, 'powerful': 226, 'able': 227, 'saw': 228, 'fair': 229, 'colleen': 230, 'stretched': 231, 'by': 232, 'tore': 233, 'under': 234, 'table': 235, 'smashed': 236, 'chaneys': 237, 'oh': 238, 'twas': 239, 'then': 240, 'runctions': 241, 'lick': 242, 'big': 243, 'phelim': 244, 'mchugh': 245, 'replied': 246, 'introduction': 247, 'kicked': 248, 'terrible': 249, 'hullabaloo': 250, 'casey': 251, 'piper': 252, 'near': 253, 'being': 254, 'strangled': 255, 'squeezed': 256, 'pipes': 257, 'bellows': 258, 'chanters': 259, 'ribbons': 260, 'entangled': 261, 'end': 262}\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 453 samples\n",
      "Epoch 1/500\n",
      "453/453 [==============================] - 5s 11ms/sample - loss: 5.5694 - accuracy: 0.0243\n",
      "Epoch 2/500\n",
      "453/453 [==============================] - 0s 334us/sample - loss: 5.5469 - accuracy: 0.0530\n",
      "Epoch 3/500\n",
      "453/453 [==============================] - 0s 314us/sample - loss: 5.5013 - accuracy: 0.0508\n",
      "Epoch 4/500\n",
      "453/453 [==============================] - 0s 709us/sample - loss: 5.3659 - accuracy: 0.0508\n",
      "Epoch 5/500\n",
      "453/453 [==============================] - 0s 366us/sample - loss: 5.1626 - accuracy: 0.0508\n",
      "Epoch 6/500\n",
      "453/453 [==============================] - 0s 339us/sample - loss: 5.0703 - accuracy: 0.0508\n",
      "Epoch 7/500\n",
      "453/453 [==============================] - 0s 344us/sample - loss: 5.0290 - accuracy: 0.0508\n",
      "Epoch 8/500\n",
      "453/453 [==============================] - 0s 382us/sample - loss: 4.9916 - accuracy: 0.0530\n",
      "Epoch 9/500\n",
      "453/453 [==============================] - 0s 453us/sample - loss: 4.9583 - accuracy: 0.0640\n",
      "Epoch 10/500\n",
      "453/453 [==============================] - 0s 552us/sample - loss: 4.9216 - accuracy: 0.0508\n",
      "Epoch 11/500\n",
      "453/453 [==============================] - 0s 520us/sample - loss: 4.8772 - accuracy: 0.0728\n",
      "Epoch 12/500\n",
      "453/453 [==============================] - 0s 488us/sample - loss: 4.8313 - accuracy: 0.0574\n",
      "Epoch 13/500\n",
      "453/453 [==============================] - 0s 370us/sample - loss: 4.7804 - accuracy: 0.0728\n",
      "Epoch 14/500\n",
      "453/453 [==============================] - 0s 347us/sample - loss: 4.7195 - accuracy: 0.0773\n",
      "Epoch 15/500\n",
      "453/453 [==============================] - 0s 403us/sample - loss: 4.6578 - accuracy: 0.0861\n",
      "Epoch 16/500\n",
      "453/453 [==============================] - 0s 355us/sample - loss: 4.6076 - accuracy: 0.0861\n",
      "Epoch 17/500\n",
      "453/453 [==============================] - 0s 357us/sample - loss: 4.5481 - accuracy: 0.0927\n",
      "Epoch 18/500\n",
      "453/453 [==============================] - 0s 525us/sample - loss: 4.5048 - accuracy: 0.0927\n",
      "Epoch 19/500\n",
      "453/453 [==============================] - 0s 310us/sample - loss: 4.4471 - accuracy: 0.0971\n",
      "Epoch 20/500\n",
      "453/453 [==============================] - 0s 290us/sample - loss: 4.3953 - accuracy: 0.1038\n",
      "Epoch 21/500\n",
      "453/453 [==============================] - 0s 520us/sample - loss: 4.3448 - accuracy: 0.1148\n",
      "Epoch 22/500\n",
      "453/453 [==============================] - 0s 392us/sample - loss: 4.2952 - accuracy: 0.1060\n",
      "Epoch 23/500\n",
      "453/453 [==============================] - 0s 362us/sample - loss: 4.2436 - accuracy: 0.1104\n",
      "Epoch 24/500\n",
      "453/453 [==============================] - 0s 358us/sample - loss: 4.2006 - accuracy: 0.1104\n",
      "Epoch 25/500\n",
      "453/453 [==============================] - 0s 362us/sample - loss: 4.1567 - accuracy: 0.1369\n",
      "Epoch 26/500\n",
      "453/453 [==============================] - 0s 356us/sample - loss: 4.1051 - accuracy: 0.1302\n",
      "Epoch 27/500\n",
      "453/453 [==============================] - 0s 381us/sample - loss: 4.0550 - accuracy: 0.1435\n",
      "Epoch 28/500\n",
      "453/453 [==============================] - 0s 357us/sample - loss: 4.0052 - accuracy: 0.1545\n",
      "Epoch 29/500\n",
      "453/453 [==============================] - 0s 415us/sample - loss: 3.9635 - accuracy: 0.1501\n",
      "Epoch 30/500\n",
      "453/453 [==============================] - 0s 295us/sample - loss: 3.9155 - accuracy: 0.1589\n",
      "Epoch 31/500\n",
      "453/453 [==============================] - 0s 312us/sample - loss: 3.8666 - accuracy: 0.1634\n",
      "Epoch 32/500\n",
      "453/453 [==============================] - 0s 379us/sample - loss: 3.8255 - accuracy: 0.1611\n",
      "Epoch 33/500\n",
      "453/453 [==============================] - 0s 450us/sample - loss: 3.7970 - accuracy: 0.1722\n",
      "Epoch 34/500\n",
      "453/453 [==============================] - 0s 357us/sample - loss: 3.7372 - accuracy: 0.1766\n",
      "Epoch 35/500\n",
      "453/453 [==============================] - 0s 352us/sample - loss: 3.7064 - accuracy: 0.1943\n",
      "Epoch 36/500\n",
      "453/453 [==============================] - 0s 488us/sample - loss: 3.6560 - accuracy: 0.2075\n",
      "Epoch 37/500\n",
      "453/453 [==============================] - 0s 359us/sample - loss: 3.6196 - accuracy: 0.2075\n",
      "Epoch 38/500\n",
      "453/453 [==============================] - 0s 347us/sample - loss: 3.5811 - accuracy: 0.2252\n",
      "Epoch 39/500\n",
      "453/453 [==============================] - 0s 407us/sample - loss: 3.5390 - accuracy: 0.2340\n",
      "Epoch 40/500\n",
      "453/453 [==============================] - 0s 363us/sample - loss: 3.5090 - accuracy: 0.2340\n",
      "Epoch 41/500\n",
      "453/453 [==============================] - 0s 360us/sample - loss: 3.4765 - accuracy: 0.2494\n",
      "Epoch 42/500\n",
      "453/453 [==============================] - 0s 347us/sample - loss: 3.4441 - accuracy: 0.2428\n",
      "Epoch 43/500\n",
      "453/453 [==============================] - 0s 350us/sample - loss: 3.4299 - accuracy: 0.2539\n",
      "Epoch 44/500\n",
      "453/453 [==============================] - 0s 456us/sample - loss: 3.3994 - accuracy: 0.2605\n",
      "Epoch 45/500\n",
      "453/453 [==============================] - 0s 388us/sample - loss: 3.3618 - accuracy: 0.2693\n",
      "Epoch 46/500\n",
      "453/453 [==============================] - 0s 393us/sample - loss: 3.3239 - accuracy: 0.2715\n",
      "Epoch 47/500\n",
      "453/453 [==============================] - 0s 388us/sample - loss: 3.2752 - accuracy: 0.2870\n",
      "Epoch 48/500\n",
      "453/453 [==============================] - 0s 360us/sample - loss: 3.2377 - accuracy: 0.2826\n",
      "Epoch 49/500\n",
      "453/453 [==============================] - 0s 358us/sample - loss: 3.1951 - accuracy: 0.3002\n",
      "Epoch 50/500\n",
      "453/453 [==============================] - 0s 382us/sample - loss: 3.1632 - accuracy: 0.3091\n",
      "Epoch 51/500\n",
      "453/453 [==============================] - 0s 334us/sample - loss: 3.1322 - accuracy: 0.3223\n",
      "Epoch 52/500\n",
      "453/453 [==============================] - 0s 369us/sample - loss: 3.1157 - accuracy: 0.3289\n",
      "Epoch 53/500\n",
      "453/453 [==============================] - 0s 401us/sample - loss: 3.0756 - accuracy: 0.3333\n",
      "Epoch 54/500\n",
      "453/453 [==============================] - 0s 352us/sample - loss: 3.0417 - accuracy: 0.3333\n",
      "Epoch 55/500\n",
      "453/453 [==============================] - 0s 388us/sample - loss: 3.0162 - accuracy: 0.3488\n",
      "Epoch 56/500\n",
      "453/453 [==============================] - 0s 502us/sample - loss: 2.9788 - accuracy: 0.3488\n",
      "Epoch 57/500\n",
      "453/453 [==============================] - 0s 579us/sample - loss: 2.9632 - accuracy: 0.3532\n",
      "Epoch 58/500\n",
      "453/453 [==============================] - 0s 453us/sample - loss: 2.9270 - accuracy: 0.3554\n",
      "Epoch 59/500\n",
      "453/453 [==============================] - 0s 379us/sample - loss: 2.8946 - accuracy: 0.3731\n",
      "Epoch 60/500\n",
      "453/453 [==============================] - 0s 476us/sample - loss: 2.8602 - accuracy: 0.3819\n",
      "Epoch 61/500\n",
      "453/453 [==============================] - 0s 418us/sample - loss: 2.8348 - accuracy: 0.3996\n",
      "Epoch 62/500\n",
      "453/453 [==============================] - 0s 361us/sample - loss: 2.8041 - accuracy: 0.3841\n",
      "Epoch 63/500\n",
      "453/453 [==============================] - 0s 383us/sample - loss: 2.7730 - accuracy: 0.3996\n",
      "Epoch 64/500\n",
      "453/453 [==============================] - 0s 354us/sample - loss: 2.7519 - accuracy: 0.4084\n",
      "Epoch 65/500\n",
      "453/453 [==============================] - 0s 350us/sample - loss: 2.7363 - accuracy: 0.4172\n",
      "Epoch 66/500\n",
      "453/453 [==============================] - 0s 368us/sample - loss: 2.7082 - accuracy: 0.4238\n",
      "Epoch 67/500\n",
      "453/453 [==============================] - 0s 434us/sample - loss: 2.6831 - accuracy: 0.4305\n",
      "Epoch 68/500\n",
      "453/453 [==============================] - 0s 382us/sample - loss: 2.6728 - accuracy: 0.4547\n",
      "Epoch 69/500\n",
      "453/453 [==============================] - 0s 413us/sample - loss: 2.6366 - accuracy: 0.4702\n",
      "Epoch 70/500\n",
      "453/453 [==============================] - 0s 415us/sample - loss: 2.6112 - accuracy: 0.4834\n",
      "Epoch 71/500\n",
      "453/453 [==============================] - 0s 374us/sample - loss: 2.5776 - accuracy: 0.4901\n",
      "Epoch 72/500\n",
      "453/453 [==============================] - 0s 372us/sample - loss: 2.5533 - accuracy: 0.4834\n",
      "Epoch 73/500\n",
      "453/453 [==============================] - 0s 362us/sample - loss: 2.5303 - accuracy: 0.5033\n",
      "Epoch 74/500\n",
      "453/453 [==============================] - 0s 362us/sample - loss: 2.5131 - accuracy: 0.4879\n",
      "Epoch 75/500\n",
      "453/453 [==============================] - 0s 373us/sample - loss: 2.4936 - accuracy: 0.5033\n",
      "Epoch 76/500\n",
      "453/453 [==============================] - 0s 329us/sample - loss: 2.5060 - accuracy: 0.4901\n",
      "Epoch 77/500\n",
      "453/453 [==============================] - 0s 292us/sample - loss: 2.4647 - accuracy: 0.5099\n",
      "Epoch 78/500\n",
      "453/453 [==============================] - 0s 502us/sample - loss: 2.4456 - accuracy: 0.5099\n",
      "Epoch 79/500\n",
      "453/453 [==============================] - 0s 365us/sample - loss: 2.4117 - accuracy: 0.5210\n",
      "Epoch 80/500\n",
      "453/453 [==============================] - 0s 346us/sample - loss: 2.3638 - accuracy: 0.5276\n",
      "Epoch 81/500\n",
      "453/453 [==============================] - 0s 333us/sample - loss: 2.3421 - accuracy: 0.5320\n",
      "Epoch 82/500\n",
      "453/453 [==============================] - 0s 533us/sample - loss: 2.3209 - accuracy: 0.5475\n",
      "Epoch 83/500\n",
      "453/453 [==============================] - 0s 351us/sample - loss: 2.2983 - accuracy: 0.5607\n",
      "Epoch 84/500\n",
      "453/453 [==============================] - 0s 346us/sample - loss: 2.2924 - accuracy: 0.5541\n",
      "Epoch 85/500\n",
      "453/453 [==============================] - 0s 452us/sample - loss: 2.2618 - accuracy: 0.5717\n",
      "Epoch 86/500\n",
      "453/453 [==============================] - 0s 458us/sample - loss: 2.2327 - accuracy: 0.5673\n",
      "Epoch 87/500\n",
      "453/453 [==============================] - 0s 441us/sample - loss: 2.2101 - accuracy: 0.5673\n",
      "Epoch 88/500\n",
      "453/453 [==============================] - 0s 452us/sample - loss: 2.1883 - accuracy: 0.5717\n",
      "Epoch 89/500\n",
      "453/453 [==============================] - 0s 415us/sample - loss: 2.1746 - accuracy: 0.5806\n",
      "Epoch 90/500\n",
      "453/453 [==============================] - 0s 463us/sample - loss: 2.1528 - accuracy: 0.5916\n",
      "Epoch 91/500\n",
      "453/453 [==============================] - 0s 523us/sample - loss: 2.1224 - accuracy: 0.5916\n",
      "Epoch 92/500\n",
      "453/453 [==============================] - 0s 451us/sample - loss: 2.1022 - accuracy: 0.6225\n",
      "Epoch 93/500\n",
      "453/453 [==============================] - 0s 433us/sample - loss: 2.0751 - accuracy: 0.6203\n",
      "Epoch 94/500\n",
      "453/453 [==============================] - 0s 388us/sample - loss: 2.0548 - accuracy: 0.6225\n",
      "Epoch 95/500\n",
      "453/453 [==============================] - 0s 395us/sample - loss: 2.0407 - accuracy: 0.6247\n",
      "Epoch 96/500\n",
      "453/453 [==============================] - 0s 404us/sample - loss: 2.0180 - accuracy: 0.6313\n",
      "Epoch 97/500\n",
      "453/453 [==============================] - 0s 397us/sample - loss: 2.0005 - accuracy: 0.6247\n",
      "Epoch 98/500\n",
      "453/453 [==============================] - 0s 432us/sample - loss: 1.9792 - accuracy: 0.6402\n",
      "Epoch 99/500\n",
      "453/453 [==============================] - 0s 361us/sample - loss: 1.9547 - accuracy: 0.6446\n",
      "Epoch 100/500\n",
      "453/453 [==============================] - 0s 452us/sample - loss: 1.9393 - accuracy: 0.6512\n",
      "Epoch 101/500\n",
      "453/453 [==============================] - 0s 453us/sample - loss: 1.9175 - accuracy: 0.6689\n",
      "Epoch 102/500\n",
      "453/453 [==============================] - 0s 407us/sample - loss: 1.8950 - accuracy: 0.6755\n",
      "Epoch 103/500\n",
      "453/453 [==============================] - 0s 645us/sample - loss: 1.8734 - accuracy: 0.6755 - loss: 1.8353 - accuracy: 0.\n",
      "Epoch 104/500\n",
      "453/453 [==============================] - 0s 426us/sample - loss: 1.8569 - accuracy: 0.6843\n",
      "Epoch 105/500\n",
      "453/453 [==============================] - 0s 491us/sample - loss: 1.8709 - accuracy: 0.6667\n",
      "Epoch 106/500\n",
      "453/453 [==============================] - 0s 424us/sample - loss: 1.8736 - accuracy: 0.6556\n",
      "Epoch 107/500\n",
      "453/453 [==============================] - 0s 415us/sample - loss: 1.8517 - accuracy: 0.6667\n",
      "Epoch 108/500\n",
      "453/453 [==============================] - 0s 380us/sample - loss: 1.8321 - accuracy: 0.6799\n",
      "Epoch 109/500\n",
      "453/453 [==============================] - 0s 496us/sample - loss: 1.8153 - accuracy: 0.6777\n",
      "Epoch 110/500\n",
      "453/453 [==============================] - 0s 515us/sample - loss: 1.7810 - accuracy: 0.6865\n",
      "Epoch 111/500\n",
      "453/453 [==============================] - 0s 411us/sample - loss: 1.7655 - accuracy: 0.6976\n",
      "Epoch 112/500\n",
      "453/453 [==============================] - 0s 365us/sample - loss: 1.7919 - accuracy: 0.6865\n",
      "Epoch 113/500\n",
      "453/453 [==============================] - 0s 382us/sample - loss: 1.7674 - accuracy: 0.6821\n",
      "Epoch 114/500\n",
      "453/453 [==============================] - 0s 413us/sample - loss: 1.7351 - accuracy: 0.6976\n",
      "Epoch 115/500\n",
      "453/453 [==============================] - 0s 447us/sample - loss: 1.7056 - accuracy: 0.7152\n",
      "Epoch 116/500\n",
      "453/453 [==============================] - 0s 416us/sample - loss: 1.6800 - accuracy: 0.7307\n",
      "Epoch 117/500\n",
      "453/453 [==============================] - 0s 398us/sample - loss: 1.6820 - accuracy: 0.7064\n",
      "Epoch 118/500\n",
      "453/453 [==============================] - 0s 394us/sample - loss: 1.6552 - accuracy: 0.7108\n",
      "Epoch 119/500\n",
      "453/453 [==============================] - 0s 511us/sample - loss: 1.6543 - accuracy: 0.7241\n",
      "Epoch 120/500\n",
      "453/453 [==============================] - 0s 364us/sample - loss: 1.6371 - accuracy: 0.7196\n",
      "Epoch 121/500\n",
      "453/453 [==============================] - 0s 442us/sample - loss: 1.6174 - accuracy: 0.7263\n",
      "Epoch 122/500\n",
      "453/453 [==============================] - 0s 397us/sample - loss: 1.5821 - accuracy: 0.7550\n",
      "Epoch 123/500\n",
      "453/453 [==============================] - 0s 392us/sample - loss: 1.5607 - accuracy: 0.7550\n",
      "Epoch 124/500\n",
      "453/453 [==============================] - 0s 372us/sample - loss: 1.5469 - accuracy: 0.7528\n",
      "Epoch 125/500\n",
      "453/453 [==============================] - 0s 436us/sample - loss: 1.5296 - accuracy: 0.7594\n",
      "Epoch 126/500\n",
      "453/453 [==============================] - 0s 486us/sample - loss: 1.5054 - accuracy: 0.7616\n",
      "Epoch 127/500\n",
      "453/453 [==============================] - 0s 468us/sample - loss: 1.4889 - accuracy: 0.7704\n",
      "Epoch 128/500\n",
      "453/453 [==============================] - 0s 481us/sample - loss: 1.4750 - accuracy: 0.7770\n",
      "Epoch 129/500\n",
      "453/453 [==============================] - 0s 495us/sample - loss: 1.4587 - accuracy: 0.7792\n",
      "Epoch 130/500\n",
      "453/453 [==============================] - 0s 445us/sample - loss: 1.4343 - accuracy: 0.7837\n",
      "Epoch 131/500\n",
      "453/453 [==============================] - 0s 420us/sample - loss: 1.4161 - accuracy: 0.7903\n",
      "Epoch 132/500\n",
      "453/453 [==============================] - 0s 559us/sample - loss: 1.4050 - accuracy: 0.8057\n",
      "Epoch 133/500\n",
      "453/453 [==============================] - 0s 635us/sample - loss: 1.3907 - accuracy: 0.7969\n",
      "Epoch 134/500\n",
      "453/453 [==============================] - 0s 452us/sample - loss: 1.3787 - accuracy: 0.7925\n",
      "Epoch 135/500\n",
      "453/453 [==============================] - 0s 477us/sample - loss: 1.3620 - accuracy: 0.8035\n",
      "Epoch 136/500\n",
      "453/453 [==============================] - 0s 590us/sample - loss: 1.3483 - accuracy: 0.8079\n",
      "Epoch 137/500\n",
      "453/453 [==============================] - 0s 579us/sample - loss: 1.3333 - accuracy: 0.8190\n",
      "Epoch 138/500\n",
      "453/453 [==============================] - 0s 426us/sample - loss: 1.3171 - accuracy: 0.8300\n",
      "Epoch 139/500\n",
      "453/453 [==============================] - 0s 451us/sample - loss: 1.3038 - accuracy: 0.8344\n",
      "Epoch 140/500\n",
      "453/453 [==============================] - 0s 538us/sample - loss: 1.2885 - accuracy: 0.8366\n",
      "Epoch 141/500\n",
      "453/453 [==============================] - 0s 490us/sample - loss: 1.2754 - accuracy: 0.8344\n",
      "Epoch 142/500\n",
      "453/453 [==============================] - 0s 475us/sample - loss: 1.2655 - accuracy: 0.8366\n",
      "Epoch 143/500\n",
      "453/453 [==============================] - 0s 445us/sample - loss: 1.2520 - accuracy: 0.8322\n",
      "Epoch 144/500\n",
      "453/453 [==============================] - 0s 441us/sample - loss: 1.2361 - accuracy: 0.8300\n",
      "Epoch 145/500\n",
      "453/453 [==============================] - 0s 590us/sample - loss: 1.2235 - accuracy: 0.8389\n",
      "Epoch 146/500\n",
      "453/453 [==============================] - 0s 656us/sample - loss: 1.2105 - accuracy: 0.8477\n",
      "Epoch 147/500\n",
      "453/453 [==============================] - 0s 473us/sample - loss: 1.2033 - accuracy: 0.8366\n",
      "Epoch 148/500\n",
      "453/453 [==============================] - 0s 741us/sample - loss: 1.1843 - accuracy: 0.8455\n",
      "Epoch 149/500\n",
      "453/453 [==============================] - 0s 487us/sample - loss: 1.1737 - accuracy: 0.8521\n",
      "Epoch 150/500\n",
      "453/453 [==============================] - 0s 479us/sample - loss: 1.1670 - accuracy: 0.8521\n",
      "Epoch 151/500\n",
      "453/453 [==============================] - 0s 444us/sample - loss: 1.1547 - accuracy: 0.8499\n",
      "Epoch 152/500\n",
      "453/453 [==============================] - 0s 439us/sample - loss: 1.1475 - accuracy: 0.8543\n",
      "Epoch 153/500\n",
      "453/453 [==============================] - 0s 456us/sample - loss: 1.1571 - accuracy: 0.8433\n",
      "Epoch 154/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 534us/sample - loss: 1.1585 - accuracy: 0.8499\n",
      "Epoch 155/500\n",
      "453/453 [==============================] - 0s 457us/sample - loss: 1.1723 - accuracy: 0.8344\n",
      "Epoch 156/500\n",
      "453/453 [==============================] - 0s 417us/sample - loss: 1.2137 - accuracy: 0.8256\n",
      "Epoch 157/500\n",
      "453/453 [==============================] - 0s 511us/sample - loss: 1.1707 - accuracy: 0.8411\n",
      "Epoch 158/500\n",
      "453/453 [==============================] - 0s 441us/sample - loss: 1.1368 - accuracy: 0.8499\n",
      "Epoch 159/500\n",
      "453/453 [==============================] - 0s 546us/sample - loss: 1.1014 - accuracy: 0.8653\n",
      "Epoch 160/500\n",
      "453/453 [==============================] - 0s 465us/sample - loss: 1.1100 - accuracy: 0.8587\n",
      "Epoch 161/500\n",
      "453/453 [==============================] - 0s 423us/sample - loss: 1.0950 - accuracy: 0.8587\n",
      "Epoch 162/500\n",
      "453/453 [==============================] - 0s 579us/sample - loss: 1.0765 - accuracy: 0.8609\n",
      "Epoch 163/500\n",
      "453/453 [==============================] - 0s 510us/sample - loss: 1.0620 - accuracy: 0.8609\n",
      "Epoch 164/500\n",
      "453/453 [==============================] - 0s 493us/sample - loss: 1.0453 - accuracy: 0.8631\n",
      "Epoch 165/500\n",
      "453/453 [==============================] - 0s 462us/sample - loss: 1.0305 - accuracy: 0.8675\n",
      "Epoch 166/500\n",
      "453/453 [==============================] - 0s 572us/sample - loss: 1.0067 - accuracy: 0.8764\n",
      "Epoch 167/500\n",
      "453/453 [==============================] - 0s 488us/sample - loss: 0.9862 - accuracy: 0.8874\n",
      "Epoch 168/500\n",
      "453/453 [==============================] - 0s 688us/sample - loss: 0.9704 - accuracy: 0.8896\n",
      "Epoch 169/500\n",
      "453/453 [==============================] - 0s 470us/sample - loss: 0.9565 - accuracy: 0.8940\n",
      "Epoch 170/500\n",
      "453/453 [==============================] - 0s 571us/sample - loss: 0.9435 - accuracy: 0.8874\n",
      "Epoch 171/500\n",
      "453/453 [==============================] - 0s 478us/sample - loss: 0.9337 - accuracy: 0.8918\n",
      "Epoch 172/500\n",
      "453/453 [==============================] - 0s 527us/sample - loss: 0.9213 - accuracy: 0.8940\n",
      "Epoch 173/500\n",
      "453/453 [==============================] - 0s 661us/sample - loss: 0.9120 - accuracy: 0.8962\n",
      "Epoch 174/500\n",
      "453/453 [==============================] - 0s 580us/sample - loss: 0.9018 - accuracy: 0.8985\n",
      "Epoch 175/500\n",
      "453/453 [==============================] - 0s 462us/sample - loss: 0.8903 - accuracy: 0.9051\n",
      "Epoch 176/500\n",
      "453/453 [==============================] - 0s 468us/sample - loss: 0.8824 - accuracy: 0.8940\n",
      "Epoch 177/500\n",
      "453/453 [==============================] - 0s 665us/sample - loss: 0.8705 - accuracy: 0.9029\n",
      "Epoch 178/500\n",
      "453/453 [==============================] - 0s 465us/sample - loss: 0.8634 - accuracy: 0.9007\n",
      "Epoch 179/500\n",
      "453/453 [==============================] - 0s 529us/sample - loss: 0.8547 - accuracy: 0.9051\n",
      "Epoch 180/500\n",
      "453/453 [==============================] - 0s 483us/sample - loss: 0.8441 - accuracy: 0.9051\n",
      "Epoch 181/500\n",
      "453/453 [==============================] - 0s 587us/sample - loss: 0.8401 - accuracy: 0.9029\n",
      "Epoch 182/500\n",
      "453/453 [==============================] - 0s 601us/sample - loss: 0.8373 - accuracy: 0.8985\n",
      "Epoch 183/500\n",
      "453/453 [==============================] - 0s 572us/sample - loss: 0.8260 - accuracy: 0.8940\n",
      "Epoch 184/500\n",
      "453/453 [==============================] - 0s 420us/sample - loss: 0.8150 - accuracy: 0.9007\n",
      "Epoch 185/500\n",
      "453/453 [==============================] - 0s 578us/sample - loss: 0.8030 - accuracy: 0.9051\n",
      "Epoch 186/500\n",
      "453/453 [==============================] - 0s 471us/sample - loss: 0.7938 - accuracy: 0.9095\n",
      "Epoch 187/500\n",
      "453/453 [==============================] - 0s 469us/sample - loss: 0.7860 - accuracy: 0.9095\n",
      "Epoch 188/500\n",
      "453/453 [==============================] - 0s 460us/sample - loss: 0.7779 - accuracy: 0.9073\n",
      "Epoch 189/500\n",
      "453/453 [==============================] - 0s 485us/sample - loss: 0.7680 - accuracy: 0.9117\n",
      "Epoch 190/500\n",
      "453/453 [==============================] - 0s 417us/sample - loss: 0.7657 - accuracy: 0.9139\n",
      "Epoch 191/500\n",
      "453/453 [==============================] - 0s 484us/sample - loss: 0.7593 - accuracy: 0.9051\n",
      "Epoch 192/500\n",
      "453/453 [==============================] - 0s 463us/sample - loss: 0.7517 - accuracy: 0.9117\n",
      "Epoch 193/500\n",
      "453/453 [==============================] - 0s 481us/sample - loss: 0.7426 - accuracy: 0.9117\n",
      "Epoch 194/500\n",
      "453/453 [==============================] - 0s 488us/sample - loss: 0.7342 - accuracy: 0.9161\n",
      "Epoch 195/500\n",
      "453/453 [==============================] - 0s 625us/sample - loss: 0.7256 - accuracy: 0.9139\n",
      "Epoch 196/500\n",
      "453/453 [==============================] - 0s 611us/sample - loss: 0.7164 - accuracy: 0.9095\n",
      "Epoch 197/500\n",
      "453/453 [==============================] - 0s 491us/sample - loss: 0.7075 - accuracy: 0.9139\n",
      "Epoch 198/500\n",
      "453/453 [==============================] - 0s 454us/sample - loss: 0.6996 - accuracy: 0.9117\n",
      "Epoch 199/500\n",
      "453/453 [==============================] - 0s 523us/sample - loss: 0.6925 - accuracy: 0.9117\n",
      "Epoch 200/500\n",
      "453/453 [==============================] - 0s 480us/sample - loss: 0.6891 - accuracy: 0.9227\n",
      "Epoch 201/500\n",
      "453/453 [==============================] - 0s 473us/sample - loss: 0.6796 - accuracy: 0.9249\n",
      "Epoch 202/500\n",
      "453/453 [==============================] - 0s 459us/sample - loss: 0.6729 - accuracy: 0.9205\n",
      "Epoch 203/500\n",
      "453/453 [==============================] - 0s 460us/sample - loss: 0.6675 - accuracy: 0.9183\n",
      "Epoch 204/500\n",
      "453/453 [==============================] - 0s 451us/sample - loss: 0.6622 - accuracy: 0.9205\n",
      "Epoch 205/500\n",
      "453/453 [==============================] - 0s 524us/sample - loss: 0.6540 - accuracy: 0.9205\n",
      "Epoch 206/500\n",
      "453/453 [==============================] - 0s 431us/sample - loss: 0.6475 - accuracy: 0.9249\n",
      "Epoch 207/500\n",
      "453/453 [==============================] - 0s 497us/sample - loss: 0.6421 - accuracy: 0.9272\n",
      "Epoch 208/500\n",
      "453/453 [==============================] - 0s 513us/sample - loss: 0.6410 - accuracy: 0.9272\n",
      "Epoch 209/500\n",
      "453/453 [==============================] - 0s 491us/sample - loss: 0.6345 - accuracy: 0.9316\n",
      "Epoch 210/500\n",
      "453/453 [==============================] - 0s 416us/sample - loss: 0.6283 - accuracy: 0.9316\n",
      "Epoch 211/500\n",
      "453/453 [==============================] - 0s 408us/sample - loss: 0.6198 - accuracy: 0.9338\n",
      "Epoch 212/500\n",
      "453/453 [==============================] - 0s 432us/sample - loss: 0.6162 - accuracy: 0.9272\n",
      "Epoch 213/500\n",
      "453/453 [==============================] - 0s 483us/sample - loss: 0.6140 - accuracy: 0.9294\n",
      "Epoch 214/500\n",
      "453/453 [==============================] - 0s 413us/sample - loss: 0.6101 - accuracy: 0.9338\n",
      "Epoch 215/500\n",
      "453/453 [==============================] - 0s 365us/sample - loss: 0.5997 - accuracy: 0.9294\n",
      "Epoch 216/500\n",
      "453/453 [==============================] - 0s 498us/sample - loss: 0.5913 - accuracy: 0.9294\n",
      "Epoch 217/500\n",
      "453/453 [==============================] - 0s 389us/sample - loss: 0.5846 - accuracy: 0.9338\n",
      "Epoch 218/500\n",
      "453/453 [==============================] - 0s 369us/sample - loss: 0.5811 - accuracy: 0.9316\n",
      "Epoch 219/500\n",
      "453/453 [==============================] - 0s 601us/sample - loss: 0.5722 - accuracy: 0.9316\n",
      "Epoch 220/500\n",
      "453/453 [==============================] - 0s 439us/sample - loss: 0.5667 - accuracy: 0.9294\n",
      "Epoch 221/500\n",
      "453/453 [==============================] - 0s 423us/sample - loss: 0.5602 - accuracy: 0.9294\n",
      "Epoch 222/500\n",
      "453/453 [==============================] - 0s 415us/sample - loss: 0.5587 - accuracy: 0.9338\n",
      "Epoch 223/500\n",
      "453/453 [==============================] - 0s 388us/sample - loss: 0.5649 - accuracy: 0.9316\n",
      "Epoch 224/500\n",
      "453/453 [==============================] - 0s 453us/sample - loss: 0.5527 - accuracy: 0.9360\n",
      "Epoch 225/500\n",
      "453/453 [==============================] - 0s 450us/sample - loss: 0.5467 - accuracy: 0.9382\n",
      "Epoch 226/500\n",
      "453/453 [==============================] - 0s 553us/sample - loss: 0.5405 - accuracy: 0.9404\n",
      "Epoch 227/500\n",
      "453/453 [==============================] - 0s 484us/sample - loss: 0.5350 - accuracy: 0.9426\n",
      "Epoch 228/500\n",
      "453/453 [==============================] - 0s 451us/sample - loss: 0.5284 - accuracy: 0.9404\n",
      "Epoch 229/500\n",
      "453/453 [==============================] - 0s 393us/sample - loss: 0.5224 - accuracy: 0.9404\n",
      "Epoch 230/500\n",
      "453/453 [==============================] - 0s 455us/sample - loss: 0.5239 - accuracy: 0.9382\n",
      "Epoch 231/500\n",
      "453/453 [==============================] - 0s 384us/sample - loss: 0.5180 - accuracy: 0.9404\n",
      "Epoch 232/500\n",
      "453/453 [==============================] - 0s 416us/sample - loss: 0.5186 - accuracy: 0.9316\n",
      "Epoch 233/500\n",
      "453/453 [==============================] - 0s 514us/sample - loss: 0.5280 - accuracy: 0.9294\n",
      "Epoch 234/500\n",
      "453/453 [==============================] - 0s 387us/sample - loss: 0.5233 - accuracy: 0.9382\n",
      "Epoch 235/500\n",
      "453/453 [==============================] - 0s 373us/sample - loss: 0.5218 - accuracy: 0.9316\n",
      "Epoch 236/500\n",
      "453/453 [==============================] - 0s 397us/sample - loss: 0.5333 - accuracy: 0.9316\n",
      "Epoch 237/500\n",
      "453/453 [==============================] - 0s 368us/sample - loss: 0.5147 - accuracy: 0.9316\n",
      "Epoch 238/500\n",
      "453/453 [==============================] - 0s 592us/sample - loss: 0.5063 - accuracy: 0.9382\n",
      "Epoch 239/500\n",
      "453/453 [==============================] - 0s 372us/sample - loss: 0.5020 - accuracy: 0.9360\n",
      "Epoch 240/500\n",
      "453/453 [==============================] - 0s 487us/sample - loss: 0.4932 - accuracy: 0.9404\n",
      "Epoch 241/500\n",
      "453/453 [==============================] - 0s 570us/sample - loss: 0.4837 - accuracy: 0.9382\n",
      "Epoch 242/500\n",
      "453/453 [==============================] - 0s 419us/sample - loss: 0.4798 - accuracy: 0.9360\n",
      "Epoch 243/500\n",
      "453/453 [==============================] - 0s 390us/sample - loss: 0.4774 - accuracy: 0.9382\n",
      "Epoch 244/500\n",
      "453/453 [==============================] - 0s 426us/sample - loss: 0.5269 - accuracy: 0.9227\n",
      "Epoch 245/500\n",
      "453/453 [==============================] - 0s 379us/sample - loss: 0.5712 - accuracy: 0.9183\n",
      "Epoch 246/500\n",
      "453/453 [==============================] - 0s 370us/sample - loss: 0.5313 - accuracy: 0.9161\n",
      "Epoch 247/500\n",
      "453/453 [==============================] - 0s 539us/sample - loss: 0.5198 - accuracy: 0.9272\n",
      "Epoch 248/500\n",
      "453/453 [==============================] - 0s 402us/sample - loss: 0.4974 - accuracy: 0.9249\n",
      "Epoch 249/500\n",
      "453/453 [==============================] - 0s 450us/sample - loss: 0.5027 - accuracy: 0.9272\n",
      "Epoch 250/500\n",
      "453/453 [==============================] - 0s 402us/sample - loss: 0.5030 - accuracy: 0.9227\n",
      "Epoch 251/500\n",
      "453/453 [==============================] - 0s 450us/sample - loss: 0.4826 - accuracy: 0.9316\n",
      "Epoch 252/500\n",
      "453/453 [==============================] - 0s 492us/sample - loss: 0.4717 - accuracy: 0.9316\n",
      "Epoch 253/500\n",
      "453/453 [==============================] - 0s 402us/sample - loss: 0.4486 - accuracy: 0.9492\n",
      "Epoch 254/500\n",
      "453/453 [==============================] - 0s 412us/sample - loss: 0.4354 - accuracy: 0.9492\n",
      "Epoch 255/500\n",
      "453/453 [==============================] - 0s 471us/sample - loss: 0.4264 - accuracy: 0.9448\n",
      "Epoch 256/500\n",
      "453/453 [==============================] - 0s 530us/sample - loss: 0.4195 - accuracy: 0.9470\n",
      "Epoch 257/500\n",
      "453/453 [==============================] - 0s 415us/sample - loss: 0.4123 - accuracy: 0.9426\n",
      "Epoch 258/500\n",
      "453/453 [==============================] - 0s 507us/sample - loss: 0.4092 - accuracy: 0.9470\n",
      "Epoch 259/500\n",
      "453/453 [==============================] - 0s 426us/sample - loss: 0.4041 - accuracy: 0.9426\n",
      "Epoch 260/500\n",
      "453/453 [==============================] - 0s 425us/sample - loss: 0.3993 - accuracy: 0.9470\n",
      "Epoch 261/500\n",
      "453/453 [==============================] - 0s 407us/sample - loss: 0.4003 - accuracy: 0.9448\n",
      "Epoch 262/500\n",
      "453/453 [==============================] - 0s 674us/sample - loss: 0.3939 - accuracy: 0.9448\n",
      "Epoch 263/500\n",
      "453/453 [==============================] - 0s 574us/sample - loss: 0.3876 - accuracy: 0.9470\n",
      "Epoch 264/500\n",
      "453/453 [==============================] - 0s 531us/sample - loss: 0.3838 - accuracy: 0.9448\n",
      "Epoch 265/500\n",
      "453/453 [==============================] - 0s 501us/sample - loss: 0.3816 - accuracy: 0.9514\n",
      "Epoch 266/500\n",
      "453/453 [==============================] - 0s 509us/sample - loss: 0.3773 - accuracy: 0.9492\n",
      "Epoch 267/500\n",
      "453/453 [==============================] - 0s 531us/sample - loss: 0.3763 - accuracy: 0.9470\n",
      "Epoch 268/500\n",
      "453/453 [==============================] - 0s 456us/sample - loss: 0.3714 - accuracy: 0.9470\n",
      "Epoch 269/500\n",
      "453/453 [==============================] - 0s 486us/sample - loss: 0.3675 - accuracy: 0.9492\n",
      "Epoch 270/500\n",
      "453/453 [==============================] - 0s 568us/sample - loss: 0.3651 - accuracy: 0.9514\n",
      "Epoch 271/500\n",
      "453/453 [==============================] - 0s 663us/sample - loss: 0.3621 - accuracy: 0.9448\n",
      "Epoch 272/500\n",
      "453/453 [==============================] - 0s 663us/sample - loss: 0.3591 - accuracy: 0.9514\n",
      "Epoch 273/500\n",
      "453/453 [==============================] - 0s 493us/sample - loss: 0.3545 - accuracy: 0.9492\n",
      "Epoch 274/500\n",
      "453/453 [==============================] - 0s 543us/sample - loss: 0.3505 - accuracy: 0.9492\n",
      "Epoch 275/500\n",
      "453/453 [==============================] - 0s 545us/sample - loss: 0.3472 - accuracy: 0.9492\n",
      "Epoch 276/500\n",
      "453/453 [==============================] - 0s 497us/sample - loss: 0.3451 - accuracy: 0.9492\n",
      "Epoch 277/500\n",
      "453/453 [==============================] - 0s 540us/sample - loss: 0.3431 - accuracy: 0.9492\n",
      "Epoch 278/500\n",
      "453/453 [==============================] - 0s 424us/sample - loss: 0.3401 - accuracy: 0.9448\n",
      "Epoch 279/500\n",
      "453/453 [==============================] - 0s 443us/sample - loss: 0.3359 - accuracy: 0.9492\n",
      "Epoch 280/500\n",
      "453/453 [==============================] - 0s 500us/sample - loss: 0.3336 - accuracy: 0.9470\n",
      "Epoch 281/500\n",
      "453/453 [==============================] - 0s 452us/sample - loss: 0.3313 - accuracy: 0.9470\n",
      "Epoch 282/500\n",
      "453/453 [==============================] - 0s 579us/sample - loss: 0.3284 - accuracy: 0.9470\n",
      "Epoch 283/500\n",
      "453/453 [==============================] - 0s 443us/sample - loss: 0.3281 - accuracy: 0.9492\n",
      "Epoch 284/500\n",
      "453/453 [==============================] - 0s 491us/sample - loss: 0.3255 - accuracy: 0.9558\n",
      "Epoch 285/500\n",
      "453/453 [==============================] - 0s 447us/sample - loss: 0.3226 - accuracy: 0.9448\n",
      "Epoch 286/500\n",
      "453/453 [==============================] - 0s 441us/sample - loss: 0.3184 - accuracy: 0.9536\n",
      "Epoch 287/500\n",
      "453/453 [==============================] - 0s 501us/sample - loss: 0.3153 - accuracy: 0.9514\n",
      "Epoch 288/500\n",
      "453/453 [==============================] - 0s 622us/sample - loss: 0.3125 - accuracy: 0.9536\n",
      "Epoch 289/500\n",
      "453/453 [==============================] - 0s 578us/sample - loss: 0.3120 - accuracy: 0.9492\n",
      "Epoch 290/500\n",
      "453/453 [==============================] - 0s 547us/sample - loss: 0.3094 - accuracy: 0.9514\n",
      "Epoch 291/500\n",
      "453/453 [==============================] - 0s 520us/sample - loss: 0.3059 - accuracy: 0.9536\n",
      "Epoch 292/500\n",
      "453/453 [==============================] - 0s 636us/sample - loss: 0.3046 - accuracy: 0.9536\n",
      "Epoch 293/500\n",
      "453/453 [==============================] - 0s 519us/sample - loss: 0.3025 - accuracy: 0.9536\n",
      "Epoch 294/500\n",
      "453/453 [==============================] - 0s 481us/sample - loss: 0.3004 - accuracy: 0.9536\n",
      "Epoch 295/500\n",
      "453/453 [==============================] - 0s 539us/sample - loss: 0.2976 - accuracy: 0.9492\n",
      "Epoch 296/500\n",
      "453/453 [==============================] - 0s 524us/sample - loss: 0.2942 - accuracy: 0.9536\n",
      "Epoch 297/500\n",
      "453/453 [==============================] - 0s 758us/sample - loss: 0.2923 - accuracy: 0.9514\n",
      "Epoch 298/500\n",
      "453/453 [==============================] - 0s 637us/sample - loss: 0.2915 - accuracy: 0.9536\n",
      "Epoch 299/500\n",
      "453/453 [==============================] - 0s 514us/sample - loss: 0.2898 - accuracy: 0.9514\n",
      "Epoch 300/500\n",
      "453/453 [==============================] - 0s 531us/sample - loss: 0.2861 - accuracy: 0.9492\n",
      "Epoch 301/500\n",
      "453/453 [==============================] - 0s 618us/sample - loss: 0.2843 - accuracy: 0.9536\n",
      "Epoch 302/500\n",
      "453/453 [==============================] - 0s 752us/sample - loss: 0.2826 - accuracy: 0.9514\n",
      "Epoch 303/500\n",
      "453/453 [==============================] - 0s 506us/sample - loss: 0.2805 - accuracy: 0.9514\n",
      "Epoch 304/500\n",
      "453/453 [==============================] - 0s 531us/sample - loss: 0.2793 - accuracy: 0.9492\n",
      "Epoch 305/500\n",
      "453/453 [==============================] - 0s 476us/sample - loss: 0.2766 - accuracy: 0.9492\n",
      "Epoch 306/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 480us/sample - loss: 0.2741 - accuracy: 0.9536\n",
      "Epoch 307/500\n",
      "453/453 [==============================] - 0s 636us/sample - loss: 0.2728 - accuracy: 0.9514\n",
      "Epoch 308/500\n",
      "453/453 [==============================] - 0s 636us/sample - loss: 0.2701 - accuracy: 0.9514\n",
      "Epoch 309/500\n",
      "453/453 [==============================] - 0s 635us/sample - loss: 0.2680 - accuracy: 0.9492\n",
      "Epoch 310/500\n",
      "453/453 [==============================] - 0s 565us/sample - loss: 0.2670 - accuracy: 0.9492\n",
      "Epoch 311/500\n",
      "453/453 [==============================] - 0s 495us/sample - loss: 0.2646 - accuracy: 0.9492\n",
      "Epoch 312/500\n",
      "453/453 [==============================] - 0s 512us/sample - loss: 0.2623 - accuracy: 0.9514\n",
      "Epoch 313/500\n",
      "453/453 [==============================] - 0s 520us/sample - loss: 0.2609 - accuracy: 0.9492\n",
      "Epoch 314/500\n",
      "453/453 [==============================] - 0s 482us/sample - loss: 0.2592 - accuracy: 0.9470\n",
      "Epoch 315/500\n",
      "453/453 [==============================] - 0s 533us/sample - loss: 0.2579 - accuracy: 0.9470\n",
      "Epoch 316/500\n",
      "453/453 [==============================] - 0s 527us/sample - loss: 0.2558 - accuracy: 0.9448\n",
      "Epoch 317/500\n",
      "453/453 [==============================] - 0s 386us/sample - loss: 0.2548 - accuracy: 0.9514\n",
      "Epoch 318/500\n",
      "453/453 [==============================] - 0s 474us/sample - loss: 0.2558 - accuracy: 0.9492\n",
      "Epoch 319/500\n",
      "453/453 [==============================] - 0s 465us/sample - loss: 0.2939 - accuracy: 0.9448\n",
      "Epoch 320/500\n",
      "453/453 [==============================] - 0s 436us/sample - loss: 0.2944 - accuracy: 0.9470\n",
      "Epoch 321/500\n",
      "453/453 [==============================] - 0s 450us/sample - loss: 0.3025 - accuracy: 0.9338\n",
      "Epoch 322/500\n",
      "453/453 [==============================] - 0s 550us/sample - loss: 0.2950 - accuracy: 0.9360\n",
      "Epoch 323/500\n",
      "453/453 [==============================] - 0s 427us/sample - loss: 0.2855 - accuracy: 0.9470\n",
      "Epoch 324/500\n",
      "453/453 [==============================] - 0s 482us/sample - loss: 0.2702 - accuracy: 0.9426\n",
      "Epoch 325/500\n",
      "453/453 [==============================] - 0s 458us/sample - loss: 0.2625 - accuracy: 0.9492\n",
      "Epoch 326/500\n",
      "453/453 [==============================] - 0s 428us/sample - loss: 0.2558 - accuracy: 0.9536\n",
      "Epoch 327/500\n",
      "453/453 [==============================] - 0s 429us/sample - loss: 0.2520 - accuracy: 0.9492\n",
      "Epoch 328/500\n",
      "453/453 [==============================] - 0s 481us/sample - loss: 0.2495 - accuracy: 0.9448\n",
      "Epoch 329/500\n",
      "453/453 [==============================] - 0s 610us/sample - loss: 0.2468 - accuracy: 0.9514\n",
      "Epoch 330/500\n",
      "453/453 [==============================] - 0s 578us/sample - loss: 0.2438 - accuracy: 0.9492\n",
      "Epoch 331/500\n",
      "453/453 [==============================] - 0s 556us/sample - loss: 0.2411 - accuracy: 0.9470\n",
      "Epoch 332/500\n",
      "453/453 [==============================] - 0s 474us/sample - loss: 0.2386 - accuracy: 0.9470\n",
      "Epoch 333/500\n",
      "453/453 [==============================] - 0s 453us/sample - loss: 0.2361 - accuracy: 0.9514\n",
      "Epoch 334/500\n",
      "453/453 [==============================] - 0s 430us/sample - loss: 0.2339 - accuracy: 0.9448\n",
      "Epoch 335/500\n",
      "453/453 [==============================] - 0s 442us/sample - loss: 0.2323 - accuracy: 0.9448\n",
      "Epoch 336/500\n",
      "453/453 [==============================] - 0s 439us/sample - loss: 0.2346 - accuracy: 0.9426\n",
      "Epoch 337/500\n",
      "453/453 [==============================] - 0s 432us/sample - loss: 0.2316 - accuracy: 0.9448\n",
      "Epoch 338/500\n",
      "453/453 [==============================] - 0s 675us/sample - loss: 0.2305 - accuracy: 0.9470\n",
      "Epoch 339/500\n",
      "453/453 [==============================] - 0s 470us/sample - loss: 0.2283 - accuracy: 0.9492\n",
      "Epoch 340/500\n",
      "453/453 [==============================] - 0s 463us/sample - loss: 0.2261 - accuracy: 0.9514\n",
      "Epoch 341/500\n",
      "453/453 [==============================] - 0s 463us/sample - loss: 0.2248 - accuracy: 0.9514\n",
      "Epoch 342/500\n",
      "453/453 [==============================] - 0s 676us/sample - loss: 0.2226 - accuracy: 0.9514\n",
      "Epoch 343/500\n",
      "453/453 [==============================] - 0s 443us/sample - loss: 0.2208 - accuracy: 0.9514\n",
      "Epoch 344/500\n",
      "453/453 [==============================] - 0s 427us/sample - loss: 0.2197 - accuracy: 0.9514\n",
      "Epoch 345/500\n",
      "453/453 [==============================] - 0s 479us/sample - loss: 0.2204 - accuracy: 0.9492\n",
      "Epoch 346/500\n",
      "453/453 [==============================] - 0s 429us/sample - loss: 0.2201 - accuracy: 0.9514\n",
      "Epoch 347/500\n",
      "453/453 [==============================] - 0s 406us/sample - loss: 0.2167 - accuracy: 0.9492\n",
      "Epoch 348/500\n",
      "453/453 [==============================] - 0s 407us/sample - loss: 0.2145 - accuracy: 0.9470\n",
      "Epoch 349/500\n",
      "453/453 [==============================] - 0s 396us/sample - loss: 0.2129 - accuracy: 0.9492\n",
      "Epoch 350/500\n",
      "453/453 [==============================] - 0s 407us/sample - loss: 0.2126 - accuracy: 0.9448\n",
      "Epoch 351/500\n",
      "453/453 [==============================] - 0s 537us/sample - loss: 0.2103 - accuracy: 0.9492\n",
      "Epoch 352/500\n",
      "453/453 [==============================] - 0s 332us/sample - loss: 0.2086 - accuracy: 0.9448\n",
      "Epoch 353/500\n",
      "453/453 [==============================] - 0s 517us/sample - loss: 0.2068 - accuracy: 0.9492\n",
      "Epoch 354/500\n",
      "453/453 [==============================] - 0s 408us/sample - loss: 0.2055 - accuracy: 0.9470\n",
      "Epoch 355/500\n",
      "453/453 [==============================] - 0s 399us/sample - loss: 0.2047 - accuracy: 0.9514\n",
      "Epoch 356/500\n",
      "453/453 [==============================] - 0s 399us/sample - loss: 0.2042 - accuracy: 0.9492\n",
      "Epoch 357/500\n",
      "453/453 [==============================] - 0s 393us/sample - loss: 0.2021 - accuracy: 0.9514\n",
      "Epoch 358/500\n",
      "453/453 [==============================] - 0s 410us/sample - loss: 0.2014 - accuracy: 0.9426\n",
      "Epoch 359/500\n",
      "453/453 [==============================] - 0s 409us/sample - loss: 0.1995 - accuracy: 0.9470\n",
      "Epoch 360/500\n",
      "453/453 [==============================] - 0s 347us/sample - loss: 0.1991 - accuracy: 0.9514\n",
      "Epoch 361/500\n",
      "453/453 [==============================] - 0s 460us/sample - loss: 0.1979 - accuracy: 0.9514\n",
      "Epoch 362/500\n",
      "453/453 [==============================] - 0s 368us/sample - loss: 0.1968 - accuracy: 0.9492\n",
      "Epoch 363/500\n",
      "453/453 [==============================] - 0s 368us/sample - loss: 0.1956 - accuracy: 0.9492\n",
      "Epoch 364/500\n",
      "453/453 [==============================] - 0s 518us/sample - loss: 0.1955 - accuracy: 0.9492\n",
      "Epoch 365/500\n",
      "453/453 [==============================] - 0s 375us/sample - loss: 0.2023 - accuracy: 0.9492\n",
      "Epoch 366/500\n",
      "453/453 [==============================] - 0s 360us/sample - loss: 0.2107 - accuracy: 0.9382\n",
      "Epoch 367/500\n",
      "453/453 [==============================] - 0s 424us/sample - loss: 0.2267 - accuracy: 0.9382\n",
      "Epoch 368/500\n",
      "453/453 [==============================] - 0s 375us/sample - loss: 0.2412 - accuracy: 0.9448\n",
      "Epoch 369/500\n",
      "453/453 [==============================] - 0s 360us/sample - loss: 0.2991 - accuracy: 0.9272\n",
      "Epoch 370/500\n",
      "453/453 [==============================] - 0s 366us/sample - loss: 0.2634 - accuracy: 0.9448\n",
      "Epoch 371/500\n",
      "453/453 [==============================] - 0s 454us/sample - loss: 0.2731 - accuracy: 0.9360\n",
      "Epoch 372/500\n",
      "453/453 [==============================] - 0s 525us/sample - loss: 0.2858 - accuracy: 0.9338\n",
      "Epoch 373/500\n",
      "453/453 [==============================] - 0s 561us/sample - loss: 0.2479 - accuracy: 0.9404\n",
      "Epoch 374/500\n",
      "453/453 [==============================] - 0s 458us/sample - loss: 0.2301 - accuracy: 0.9470\n",
      "Epoch 375/500\n",
      "453/453 [==============================] - 0s 409us/sample - loss: 0.2141 - accuracy: 0.9514\n",
      "Epoch 376/500\n",
      "453/453 [==============================] - 0s 417us/sample - loss: 0.2211 - accuracy: 0.9404\n",
      "Epoch 377/500\n",
      "453/453 [==============================] - 0s 424us/sample - loss: 0.2176 - accuracy: 0.9426\n",
      "Epoch 378/500\n",
      "453/453 [==============================] - 0s 441us/sample - loss: 0.2243 - accuracy: 0.9426\n",
      "Epoch 379/500\n",
      "453/453 [==============================] - 0s 395us/sample - loss: 0.2041 - accuracy: 0.9426\n",
      "Epoch 380/500\n",
      "453/453 [==============================] - 0s 391us/sample - loss: 0.1965 - accuracy: 0.9470\n",
      "Epoch 381/500\n",
      "453/453 [==============================] - 0s 375us/sample - loss: 0.1932 - accuracy: 0.9470\n",
      "Epoch 382/500\n",
      "453/453 [==============================] - 0s 457us/sample - loss: 0.1864 - accuracy: 0.9492\n",
      "Epoch 383/500\n",
      "453/453 [==============================] - 0s 389us/sample - loss: 0.1834 - accuracy: 0.9514\n",
      "Epoch 384/500\n",
      "453/453 [==============================] - 0s 400us/sample - loss: 0.1818 - accuracy: 0.9492\n",
      "Epoch 385/500\n",
      "453/453 [==============================] - 0s 398us/sample - loss: 0.1812 - accuracy: 0.9492\n",
      "Epoch 386/500\n",
      "453/453 [==============================] - 0s 438us/sample - loss: 0.1809 - accuracy: 0.9426\n",
      "Epoch 387/500\n",
      "453/453 [==============================] - 0s 539us/sample - loss: 0.1804 - accuracy: 0.9514\n",
      "Epoch 388/500\n",
      "453/453 [==============================] - 0s 426us/sample - loss: 0.1779 - accuracy: 0.9448\n",
      "Epoch 389/500\n",
      "453/453 [==============================] - 0s 401us/sample - loss: 0.1775 - accuracy: 0.9492\n",
      "Epoch 390/500\n",
      "453/453 [==============================] - 0s 400us/sample - loss: 0.1759 - accuracy: 0.9536\n",
      "Epoch 391/500\n",
      "453/453 [==============================] - 0s 370us/sample - loss: 0.1751 - accuracy: 0.9492\n",
      "Epoch 392/500\n",
      "453/453 [==============================] - 0s 412us/sample - loss: 0.1742 - accuracy: 0.9470\n",
      "Epoch 393/500\n",
      "453/453 [==============================] - 0s 404us/sample - loss: 0.1737 - accuracy: 0.9514\n",
      "Epoch 394/500\n",
      "453/453 [==============================] - 0s 549us/sample - loss: 0.1735 - accuracy: 0.9514\n",
      "Epoch 395/500\n",
      "453/453 [==============================] - 0s 417us/sample - loss: 0.1715 - accuracy: 0.9470\n",
      "Epoch 396/500\n",
      "453/453 [==============================] - 0s 408us/sample - loss: 0.1702 - accuracy: 0.9492\n",
      "Epoch 397/500\n",
      "453/453 [==============================] - 0s 380us/sample - loss: 0.1697 - accuracy: 0.9492\n",
      "Epoch 398/500\n",
      "453/453 [==============================] - 0s 436us/sample - loss: 0.1697 - accuracy: 0.9470\n",
      "Epoch 399/500\n",
      "453/453 [==============================] - 0s 390us/sample - loss: 0.1686 - accuracy: 0.9536\n",
      "Epoch 400/500\n",
      "453/453 [==============================] - 0s 401us/sample - loss: 0.1677 - accuracy: 0.9448\n",
      "Epoch 401/500\n",
      "453/453 [==============================] - 0s 383us/sample - loss: 0.1668 - accuracy: 0.9470\n",
      "Epoch 402/500\n",
      "453/453 [==============================] - 0s 372us/sample - loss: 0.1658 - accuracy: 0.9514\n",
      "Epoch 403/500\n",
      "453/453 [==============================] - 0s 431us/sample - loss: 0.1646 - accuracy: 0.9492\n",
      "Epoch 404/500\n",
      "453/453 [==============================] - 0s 383us/sample - loss: 0.1640 - accuracy: 0.9514\n",
      "Epoch 405/500\n",
      "453/453 [==============================] - 0s 470us/sample - loss: 0.1630 - accuracy: 0.9492\n",
      "Epoch 406/500\n",
      "453/453 [==============================] - 0s 363us/sample - loss: 0.1624 - accuracy: 0.9492\n",
      "Epoch 407/500\n",
      "453/453 [==============================] - 0s 401us/sample - loss: 0.1619 - accuracy: 0.9448\n",
      "Epoch 408/500\n",
      "453/453 [==============================] - 0s 361us/sample - loss: 0.1611 - accuracy: 0.9492\n",
      "Epoch 409/500\n",
      "453/453 [==============================] - 0s 357us/sample - loss: 0.1611 - accuracy: 0.9426\n",
      "Epoch 410/500\n",
      "453/453 [==============================] - 0s 434us/sample - loss: 0.1602 - accuracy: 0.9470\n",
      "Epoch 411/500\n",
      "453/453 [==============================] - 0s 401us/sample - loss: 0.1596 - accuracy: 0.9470\n",
      "Epoch 412/500\n",
      "453/453 [==============================] - 0s 383us/sample - loss: 0.1592 - accuracy: 0.9536\n",
      "Epoch 413/500\n",
      "453/453 [==============================] - 0s 379us/sample - loss: 0.1586 - accuracy: 0.9536\n",
      "Epoch 414/500\n",
      "453/453 [==============================] - 0s 399us/sample - loss: 0.1581 - accuracy: 0.9448\n",
      "Epoch 415/500\n",
      "453/453 [==============================] - 0s 317us/sample - loss: 0.1570 - accuracy: 0.9492\n",
      "Epoch 416/500\n",
      "453/453 [==============================] - 0s 410us/sample - loss: 0.1564 - accuracy: 0.9470\n",
      "Epoch 417/500\n",
      "453/453 [==============================] - 0s 363us/sample - loss: 0.1562 - accuracy: 0.9492\n",
      "Epoch 418/500\n",
      "453/453 [==============================] - 0s 365us/sample - loss: 0.1549 - accuracy: 0.9448\n",
      "Epoch 419/500\n",
      "453/453 [==============================] - 0s 498us/sample - loss: 0.1544 - accuracy: 0.9470\n",
      "Epoch 420/500\n",
      "453/453 [==============================] - 0s 369us/sample - loss: 0.1538 - accuracy: 0.9492\n",
      "Epoch 421/500\n",
      "453/453 [==============================] - 0s 399us/sample - loss: 0.1543 - accuracy: 0.9492\n",
      "Epoch 422/500\n",
      "453/453 [==============================] - 0s 373us/sample - loss: 0.1535 - accuracy: 0.9492\n",
      "Epoch 423/500\n",
      "453/453 [==============================] - 0s 459us/sample - loss: 0.1526 - accuracy: 0.9536\n",
      "Epoch 424/500\n",
      "453/453 [==============================] - 0s 385us/sample - loss: 0.1519 - accuracy: 0.9514\n",
      "Epoch 425/500\n",
      "453/453 [==============================] - 0s 391us/sample - loss: 0.1511 - accuracy: 0.9492\n",
      "Epoch 426/500\n",
      "453/453 [==============================] - 0s 398us/sample - loss: 0.1508 - accuracy: 0.9470\n",
      "Epoch 427/500\n",
      "453/453 [==============================] - 0s 401us/sample - loss: 0.1499 - accuracy: 0.9514\n",
      "Epoch 428/500\n",
      "453/453 [==============================] - 0s 375us/sample - loss: 0.1494 - accuracy: 0.9492\n",
      "Epoch 429/500\n",
      "453/453 [==============================] - 0s 377us/sample - loss: 0.1489 - accuracy: 0.9470\n",
      "Epoch 430/500\n",
      "453/453 [==============================] - 0s 388us/sample - loss: 0.1487 - accuracy: 0.9492\n",
      "Epoch 431/500\n",
      "453/453 [==============================] - 0s 347us/sample - loss: 0.1485 - accuracy: 0.9448\n",
      "Epoch 432/500\n",
      "453/453 [==============================] - 0s 524us/sample - loss: 0.1474 - accuracy: 0.9448\n",
      "Epoch 433/500\n",
      "453/453 [==============================] - 0s 414us/sample - loss: 0.1472 - accuracy: 0.9470\n",
      "Epoch 434/500\n",
      "453/453 [==============================] - 0s 416us/sample - loss: 0.1466 - accuracy: 0.9470\n",
      "Epoch 435/500\n",
      "453/453 [==============================] - 0s 394us/sample - loss: 0.1473 - accuracy: 0.9470\n",
      "Epoch 436/500\n",
      "453/453 [==============================] - 0s 407us/sample - loss: 0.1466 - accuracy: 0.9426\n",
      "Epoch 437/500\n",
      "453/453 [==============================] - 0s 363us/sample - loss: 0.1461 - accuracy: 0.9470\n",
      "Epoch 438/500\n",
      "453/453 [==============================] - 0s 447us/sample - loss: 0.1521 - accuracy: 0.9514\n",
      "Epoch 439/500\n",
      "453/453 [==============================] - 0s 663us/sample - loss: 0.1478 - accuracy: 0.9470\n",
      "Epoch 440/500\n",
      "453/453 [==============================] - 0s 434us/sample - loss: 0.1483 - accuracy: 0.9492\n",
      "Epoch 441/500\n",
      "453/453 [==============================] - 0s 705us/sample - loss: 0.1473 - accuracy: 0.9492\n",
      "Epoch 442/500\n",
      "453/453 [==============================] - 0s 539us/sample - loss: 0.1436 - accuracy: 0.9536\n",
      "Epoch 443/500\n",
      "453/453 [==============================] - 0s 383us/sample - loss: 0.1429 - accuracy: 0.9492\n",
      "Epoch 444/500\n",
      "453/453 [==============================] - 0s 498us/sample - loss: 0.1422 - accuracy: 0.9492\n",
      "Epoch 445/500\n",
      "453/453 [==============================] - 0s 523us/sample - loss: 0.1415 - accuracy: 0.9448\n",
      "Epoch 446/500\n",
      "453/453 [==============================] - 0s 375us/sample - loss: 0.1411 - accuracy: 0.9492\n",
      "Epoch 447/500\n",
      "453/453 [==============================] - 0s 360us/sample - loss: 0.1407 - accuracy: 0.9470\n",
      "Epoch 448/500\n",
      "453/453 [==============================] - 0s 381us/sample - loss: 0.1450 - accuracy: 0.9514\n",
      "Epoch 449/500\n",
      "453/453 [==============================] - 0s 364us/sample - loss: 0.1526 - accuracy: 0.9404\n",
      "Epoch 450/500\n",
      "453/453 [==============================] - 0s 391us/sample - loss: 0.1471 - accuracy: 0.9514\n",
      "Epoch 451/500\n",
      "453/453 [==============================] - 0s 367us/sample - loss: 0.1436 - accuracy: 0.9492\n",
      "Epoch 452/500\n",
      "453/453 [==============================] - 0s 372us/sample - loss: 0.1434 - accuracy: 0.9492\n",
      "Epoch 453/500\n",
      "453/453 [==============================] - 0s 506us/sample - loss: 0.1499 - accuracy: 0.9404\n",
      "Epoch 454/500\n",
      "453/453 [==============================] - 0s 464us/sample - loss: 0.1452 - accuracy: 0.9382\n",
      "Epoch 455/500\n",
      "453/453 [==============================] - 0s 380us/sample - loss: 0.1421 - accuracy: 0.9426\n",
      "Epoch 456/500\n",
      "453/453 [==============================] - 0s 304us/sample - loss: 0.1401 - accuracy: 0.9514\n",
      "Epoch 457/500\n",
      "453/453 [==============================] - 0s 457us/sample - loss: 0.1393 - accuracy: 0.9514\n",
      "Epoch 458/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 519us/sample - loss: 0.1376 - accuracy: 0.9470\n",
      "Epoch 459/500\n",
      "453/453 [==============================] - 0s 390us/sample - loss: 0.1369 - accuracy: 0.9514\n",
      "Epoch 460/500\n",
      "453/453 [==============================] - 0s 382us/sample - loss: 0.1366 - accuracy: 0.9470\n",
      "Epoch 461/500\n",
      "453/453 [==============================] - 0s 378us/sample - loss: 0.1367 - accuracy: 0.9514\n",
      "Epoch 462/500\n",
      "453/453 [==============================] - 0s 377us/sample - loss: 0.1364 - accuracy: 0.9492\n",
      "Epoch 463/500\n",
      "453/453 [==============================] - 0s 364us/sample - loss: 0.1361 - accuracy: 0.9492\n",
      "Epoch 464/500\n",
      "453/453 [==============================] - 0s 374us/sample - loss: 0.1360 - accuracy: 0.9470\n",
      "Epoch 465/500\n",
      "453/453 [==============================] - 0s 383us/sample - loss: 0.1349 - accuracy: 0.9514\n",
      "Epoch 466/500\n",
      "453/453 [==============================] - 0s 392us/sample - loss: 0.1353 - accuracy: 0.9492\n",
      "Epoch 467/500\n",
      "453/453 [==============================] - 0s 326us/sample - loss: 0.1347 - accuracy: 0.9448\n",
      "Epoch 468/500\n",
      "453/453 [==============================] - 0s 310us/sample - loss: 0.1418 - accuracy: 0.9514\n",
      "Epoch 469/500\n",
      "453/453 [==============================] - 0s 425us/sample - loss: 0.1393 - accuracy: 0.9536\n",
      "Epoch 470/500\n",
      "453/453 [==============================] - 0s 376us/sample - loss: 0.1364 - accuracy: 0.9536\n",
      "Epoch 471/500\n",
      "453/453 [==============================] - 0s 362us/sample - loss: 0.1333 - accuracy: 0.9536\n",
      "Epoch 472/500\n",
      "453/453 [==============================] - 0s 461us/sample - loss: 0.1319 - accuracy: 0.9536\n",
      "Epoch 473/500\n",
      "453/453 [==============================] - 0s 382us/sample - loss: 0.1328 - accuracy: 0.9514\n",
      "Epoch 474/500\n",
      "453/453 [==============================] - 0s 358us/sample - loss: 0.1316 - accuracy: 0.9536\n",
      "Epoch 475/500\n",
      "453/453 [==============================] - 0s 430us/sample - loss: 0.1307 - accuracy: 0.9470\n",
      "Epoch 476/500\n",
      "453/453 [==============================] - 0s 374us/sample - loss: 0.1299 - accuracy: 0.9448\n",
      "Epoch 477/500\n",
      "453/453 [==============================] - 0s 367us/sample - loss: 0.1300 - accuracy: 0.9492\n",
      "Epoch 478/500\n",
      "453/453 [==============================] - 0s 364us/sample - loss: 0.1289 - accuracy: 0.9514\n",
      "Epoch 479/500\n",
      "453/453 [==============================] - 0s 430us/sample - loss: 0.1287 - accuracy: 0.9470\n",
      "Epoch 480/500\n",
      "453/453 [==============================] - 0s 424us/sample - loss: 0.1292 - accuracy: 0.9448\n",
      "Epoch 481/500\n",
      "453/453 [==============================] - 0s 396us/sample - loss: 0.1288 - accuracy: 0.9448\n",
      "Epoch 482/500\n",
      "453/453 [==============================] - 0s 370us/sample - loss: 0.1287 - accuracy: 0.9470\n",
      "Epoch 483/500\n",
      "453/453 [==============================] - 0s 370us/sample - loss: 0.1288 - accuracy: 0.9470\n",
      "Epoch 484/500\n",
      "453/453 [==============================] - 0s 385us/sample - loss: 0.1280 - accuracy: 0.9492\n",
      "Epoch 485/500\n",
      "453/453 [==============================] - 0s 350us/sample - loss: 0.1270 - accuracy: 0.9492\n",
      "Epoch 486/500\n",
      "453/453 [==============================] - 0s 413us/sample - loss: 0.1267 - accuracy: 0.9470\n",
      "Epoch 487/500\n",
      "453/453 [==============================] - 0s 378us/sample - loss: 0.1268 - accuracy: 0.9470\n",
      "Epoch 488/500\n",
      "453/453 [==============================] - 0s 368us/sample - loss: 0.1260 - accuracy: 0.9426\n",
      "Epoch 489/500\n",
      "453/453 [==============================] - 0s 463us/sample - loss: 0.1255 - accuracy: 0.9470\n",
      "Epoch 490/500\n",
      "453/453 [==============================] - 0s 458us/sample - loss: 0.1253 - accuracy: 0.9448\n",
      "Epoch 491/500\n",
      "453/453 [==============================] - 0s 521us/sample - loss: 0.1256 - accuracy: 0.9426\n",
      "Epoch 492/500\n",
      "453/453 [==============================] - 0s 442us/sample - loss: 0.1250 - accuracy: 0.9514\n",
      "Epoch 493/500\n",
      "453/453 [==============================] - 0s 395us/sample - loss: 0.1247 - accuracy: 0.9514\n",
      "Epoch 494/500\n",
      "453/453 [==============================] - 0s 516us/sample - loss: 0.1244 - accuracy: 0.9514\n",
      "Epoch 495/500\n",
      "453/453 [==============================] - 0s 442us/sample - loss: 0.1236 - accuracy: 0.9514\n",
      "Epoch 496/500\n",
      "453/453 [==============================] - 0s 418us/sample - loss: 0.1234 - accuracy: 0.9492\n",
      "Epoch 497/500\n",
      "453/453 [==============================] - 0s 549us/sample - loss: 0.1236 - accuracy: 0.9514\n",
      "Epoch 498/500\n",
      "453/453 [==============================] - 0s 412us/sample - loss: 0.1230 - accuracy: 0.9492\n",
      "Epoch 499/500\n",
      "453/453 [==============================] - 0s 420us/sample - loss: 0.1231 - accuracy: 0.9448\n",
      "Epoch 500/500\n",
      "453/453 [==============================] - 0s 429us/sample - loss: 0.1226 - accuracy: 0.9470\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(total_words, 64, input_length=max_sequence_len-1))\n",
    "model.add(Bidirectional(LSTM(20)))\n",
    "model.add(Dense(total_words, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(xs, ys, epochs=500, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_graphs(history, string):\n",
    "    plt.plot(history.history[string])\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(string)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_graphs(history, 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Laurence went to dublin the ructions of lanigans ball ball as round as rose rose ladies glisten together entangled entangled were glisten strangled satisfaction entangled entangled entangled twas eyes academy strangled strangled strangled academy odaly together entangled entangled dublin were strangled strangled strangled strangled strangled strangled youd declared glisten glisten nelly of girls entangled entangled oh row of your eyes glisten glisten glisten academy academy academy together at lanigans new all entangled entangled entangled all entangled all entangled all the ructions of the ructions of lanigans ball of they as bellows ladies ladies water strangled strangled satisfaction at entangled all entangled entangled twas eyes\n"
     ]
    }
   ],
   "source": [
    "seed_text = \"Laurence went to dublin\"\n",
    "next_words = 100\n",
    "  \n",
    "for _ in range(next_words):\n",
    "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "    predicted = model.predict_classes(token_list, verbose=0)\n",
    "    output_word = \"\"\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == predicted:\n",
    "            output_word = word\n",
    "            break\n",
    "    seed_text += \" \" + output_word\n",
    "print(seed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
