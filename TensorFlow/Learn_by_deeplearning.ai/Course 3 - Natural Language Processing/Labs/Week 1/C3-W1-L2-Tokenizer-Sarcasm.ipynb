{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-07-24 17:49:30--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/sarcasm.json\n",
      "正在解析主机 storage.googleapis.com (storage.googleapis.com)... 34.64.4.16, 34.64.4.80, 34.64.4.112\n",
      "正在连接 storage.googleapis.com (storage.googleapis.com)|34.64.4.16|:443... 已连接。\n",
      "已发出 HTTP 请求，正在等待回应... 200 OK\n",
      "长度：5643545 (5.4M) [application/json]\n",
      "正在保存至: “/tmp/sarcasm.json”\n",
      "\n",
      "/tmp/sarcasm.json   100%[===================>]   5.38M   310KB/s  用时 20s       \n",
      "\n",
      "2020-07-24 17:49:52 (272 KB/s) - 已保存 “/tmp/sarcasm.json” [5643545/5643545])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget --no-check-certificate \\\n",
    "    https://storage.googleapis.com/laurencemoroney-blog.appspot.com/sarcasm.json \\\n",
    "    -O /tmp/sarcasm.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29657\n",
      "[  145   838     2   907  1749  2093   582  4719   221   143    39    46\n",
      "     2 10736     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0]\n",
      "mom starting to fear son's web series closest thing she will have to grandchild\n",
      "(26709, 40)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(\"/tmp/sarcasm.json\", 'r') as f:\n",
    "    datastore = json.load(f)\n",
    "\n",
    "\n",
    "sentences = [] \n",
    "labels = []\n",
    "urls = []\n",
    "for item in datastore:\n",
    "    sentences.append(item['headline'])\n",
    "    labels.append(item['is_sarcastic'])\n",
    "    urls.append(item['article_link'])\n",
    "\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "tokenizer = Tokenizer(oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print(len(word_index))\n",
    "# print(word_index)\n",
    "sequences = tokenizer.texts_to_sequences(sentences)\n",
    "padded = pad_sequences(sequences, padding='post')\n",
    "print(padded[2])\n",
    "print(sentences[2])\n",
    "print(padded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
